{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "# def read_secret(secret_name):\n",
    "#     secret_path = os.getenv(secret_name)\n",
    "#     try:\n",
    "#         with open(secret_path, 'r') as file:\n",
    "#             return file.read().strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {secret_name}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# INFLUXDB_USERNAME = read_secret('DOCKER_INFLUXDB_INIT_USERNAME_FILE')\n",
    "# INFLUXDB_PASSWORD = read_secret('DOCKER_INFLUXDB_INIT_PASSWORD_FILE')\n",
    "# INFLUXDB_TOKEN = read_secret('DOCKER_INFLUXDB_INIT_ADMIN_TOKEN_FILE')\n",
    "\n",
    "# INFLUXDB_ORG = os.getenv('DOCKER_INFLUXDB_INIT_ORG')\n",
    "# INFLUXDB_BUCKET = os.getenv('DOCKER_INFLUXDB_INIT_BUCKET')\n",
    "# INFLUXDB_URL = os.getenv('INFLUXDB_URL', 'http://influxdb:8086') \n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.query_api import QueryOptions\n",
    "import pandas as pd\n",
    "import os\n",
    "INFLUXDB_USERNAME=\"admin\"\n",
    "INFLUXDB_PASSWORD=\"password\"\n",
    "INFLUXDB_TOKEN=\"G3UtSut5Kv-RuT32yh27StdDCrl4fu3uzxPLzdias8vFsNzyzgfw5kIX9iGvtLctAXpZjFItOUwA65YWtk_5fg==\"\n",
    "INFLUXDB_ORG=\"example_org\"\n",
    "INFLUXDB_BUCKET=\"example_bucket\"\n",
    "INFLUXDB_URL=\"http://localhost:8086\"\n",
    "\n",
    "client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)\n",
    "\n",
    "# Create a QueryAPI instance\n",
    "query_api = client.query_api(query_options=QueryOptions(profilers=[]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "query = f'''\n",
    "from(bucket: \"{INFLUXDB_BUCKET}\")\n",
    "        |> range(start: -5h)\n",
    "        |> filter(fn: (r) => r._measurement == \"heart_rate\")\n",
    "        |> filter(fn: (r) => r._field == \"noisy\" or r._field == \"original_time\")\n",
    "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "        |> keep(columns: [\"noisy\", \"original_time\"])\n",
    "'''\n",
    "checkpoint_df = query_api.query_data_frame(query=query)\n",
    "client.close()\n",
    "checkpoint_df.drop(columns=['table','result'],inplace=True)\n",
    "checkpoint_df['original_time'] = pd.to_datetime(checkpoint_df['original_time'])\n",
    "latest_time = checkpoint_df['original_time'].max()\n",
    "one_year_before_latest = latest_time - pd.DateOffset(years=1)\n",
    "training_df = checkpoint_df[checkpoint_df['original_time'] >= one_year_before_latest]\n",
    "\n",
    "\n",
    "\n",
    "# HERE TRAIN DATA USING TRAINING DF\n",
    "# trainanomalymodel(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15T10:02:05.307399+00:00\n",
      "        noisy             original_time\n",
      "0   63.564632 2022-06-13 18:00:00+00:00\n",
      "1   63.018735 2022-06-14 09:00:00+00:00\n",
      "2   63.673516 2022-06-14 12:00:00+00:00\n",
      "3   63.469121 2022-06-14 15:00:00+00:00\n",
      "4   63.836436 2022-06-14 18:00:00+00:00\n",
      "5   61.043874 2022-06-15 09:00:00+00:00\n",
      "6   60.598961 2022-06-15 12:00:00+00:00\n",
      "7   60.869564 2022-06-15 15:00:00+00:00\n",
      "8   60.705201 2022-06-15 18:00:00+00:00\n",
      "9   61.193341 2022-06-16 09:00:00+00:00\n",
      "10  61.037952 2022-06-16 12:00:00+00:00\n",
      "11  61.067039 2022-06-16 15:00:00+00:00\n",
      "12  60.969226 2022-06-16 18:00:00+00:00\n",
      "13  57.462581 2022-06-17 09:00:00+00:00\n",
      "14  57.635690 2022-06-17 12:00:00+00:00\n",
      "15  57.939654 2022-06-17 15:00:00+00:00\n",
      "16  57.995920 2022-06-17 18:00:00+00:00\n",
      "17  59.530087 2022-06-18 09:00:00+00:00\n",
      "18  59.437133 2022-06-18 12:00:00+00:00\n",
      "19  59.359975 2022-06-18 15:00:00+00:00\n",
      "20  60.244319 2022-06-18 18:00:00+00:00\n",
      "21  57.581128 2022-06-19 09:00:00+00:00\n",
      "22  58.253188 2022-06-19 12:00:00+00:00\n",
      "23  58.341501 2022-06-19 15:00:00+00:00\n",
      "24  58.046356 2022-06-19 18:00:00+00:00\n",
      "25  57.384845 2022-06-20 09:00:00+00:00\n",
      "26  57.511496 2022-06-20 12:00:00+00:00\n",
      "27  57.704859 2022-06-20 15:00:00+00:00\n",
      "28  58.241423 2022-06-20 18:00:00+00:00\n",
      "29  61.542244 2022-06-21 09:00:00+00:00\n",
      "30  60.781354 2022-06-21 12:00:00+00:00\n",
      "31  61.675816 2022-06-21 15:00:00+00:00\n",
      "32  61.255087 2022-06-21 18:00:00+00:00\n",
      "33  60.087798 2022-06-22 09:00:00+00:00\n",
      "34  60.239361 2022-06-22 12:00:00+00:00\n",
      "35  60.191410 2022-06-22 15:00:00+00:00\n",
      "36  60.167187 2022-06-22 18:00:00+00:00\n",
      "37  61.196494 2022-06-23 09:00:00+00:00\n",
      "38  61.112748 2022-06-23 12:00:00+00:00\n",
      "39  61.122631 2022-06-23 15:00:00+00:00\n",
      "40  61.066880 2022-06-23 18:00:00+00:00\n",
      "41  60.792225 2022-06-24 09:00:00+00:00\n",
      "42  60.918366 2022-06-24 12:00:00+00:00\n",
      "43  60.794942 2022-06-24 15:00:00+00:00\n",
      "44  60.939983 2022-06-24 18:00:00+00:00\n",
      "45  61.149171 2022-06-25 09:00:00+00:00\n",
      "46  61.808403 2022-06-25 12:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timezone\n",
    "import time\n",
    "\n",
    "last_pull_time = datetime.utcnow().replace(tzinfo=timezone.utc) - pd.DateOffset(second=5)\n",
    "\n",
    "print(last_pull_time.isoformat())\n",
    "while True:\n",
    "    # Build the query with dynamic start time\n",
    "    query = f'''\n",
    "    from(bucket: \"{INFLUXDB_BUCKET}\")\n",
    "        |> range(start: {last_pull_time.isoformat()})\n",
    "        |> filter(fn: (r) => r._measurement == \"heart_rate\")\n",
    "        |> filter(fn: (r) => r._field == \"noisy\" or r._field == \"original_time\")\n",
    "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "        |> keep(columns: [\"noisy\", \"original_time\"])\n",
    "    '''\n",
    "    new_data = query_api.query_data_frame(query=query)\n",
    "    \n",
    "    if not new_data.empty:\n",
    "        new_data.drop(columns=['table', 'result'], inplace=True)\n",
    "        new_data['original_time'] = pd.to_datetime(new_data['original_time'])\n",
    "        \n",
    "        # HERE TEST THIS NEW DATA FOR ANOMALY DETECTION.\n",
    "        # detect_anomalies\n",
    "        # ADD NON_ANOMALY ROWS TO ANOTHER DATAFRAME\n",
    "        # IF ANOTHERDATAFRAME HAS 1 YEAR OF DATA, TRAIN DATA ON THAT.        \n",
    "        #checkpoint_df = pd.concat([checkpoint_df, new_data])\n",
    "        print(new_data)\n",
    "        # Update the last pull time\n",
    "        #last_pull_time = latest_time\n",
    "        last_pull_time = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "\n",
    "    # Wait for 5 seconds before the next pull\n",
    "    break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6573 entries, 0 to 6572\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   noisy          6564 non-null   float64            \n",
      " 1   original_time  6573 non-null   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), float64(1)\n",
      "memory usage: 102.8 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_time = result['original_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-08-09 12:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
